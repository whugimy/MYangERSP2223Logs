# MYangERSP2223Logs
My logs for ERSP 2022-2023

# Week 2

### Goals
- [x] Read Unicorn research paper
- [ ] Have first research group meeting / ~~get response on when mentor meetings will occur~~ meeting will occur on 4PM PST October 7
- [ ] Get link to logs on the CS110 website

### Unicorn Research Paper Notes:
#### Abstract:
Existing ML solutions for networking problems are not being implemented; this is because these ML artifacts are often unreliable. The paper makes the claim that these ML artifacts have poor quality due to their training data: the process of collecting data for ML is described as "one-off," "fragmented," and with two key issues: it is too difficult to compile data from different sources to use as training material for the same problem, and simultaneously too difficult to apply data from a single source to mutliple problems. The paper proposes a solution called "Unicorn," which sreamlines the process of collecting data from one source for multiple problems.

#### Introduction:
Network operators have, at any point, only a partial understanding of the state of their network, and they constantly need to make decisions to solve some arbitrary "problems." There seems to be industry interest in applying ML techniques to better make these decisions, but existing ML solutions are not being applied. This is because the industry feels wary of ML's innate "black-box" nature. The "black-box" issue refers to our lack of understanding regarding neural networks. Although we can use them, we have almost no insight into how they actually make decisions. The ML artifacts created with given data are simply too complicated for a human to understand. Industry members must then rely solely on the algorithm's results to determine its feasibility. In order for the algorithm to be "trustworthy," it must be able to adapt to and properly process information outside of its training set. Existing ML solutions struggle to do so, as they are often trained with data from one, specific source, and often do not correctly generalize to external data.

Everything beyond the background on the problem being solved describes Unicorn's specifications and how it would help solve the above problems. However, I don't have any technical understanding of ML models or data collection pipelines as they are described in the paper.

#### Experimental Process:
The paper describes the process of implementing a Unicorn prototype. The paper describes Unicorn's implementation being split into a frontend and backend. The frontend serves as an interface for the user to select and configure data-collection pipelines. An operation titled "execute" will connect these pipelines to Unicorn's backend and begin processing. Unicorn's backend consists of the following components: 
1. Connectivity-manager: connects Unicorn's front and backend
2. Compiler: translates data-collection pipeline's general data into specific forms depending on what problem the artifact will be trained for, then processes the data (not sure how)
3. Runtime: serves as sort of a general OS that handles queries and displays runtime info
4. Datastore: provides memory for the runtime to manage

#### Background:
The paper's background and motivation segment discusses two core concepts: the "trust problem" in existing ML approaches, as well as existing data-collection pipelines. The core issue in the described "trust problem" is simple: ML artifacts are unable to generalize beyond their training data set; the paper describes them as unaware of any potential biases that result from their training set. As a result, these ML artifacts fail in two key ways: there are "structural failure modes" where the model consistently provides an incorrect output (the paper calls this a misalignment between selected and desired predictors), then there are "underspecificed failure modes," where the training data doesn't contain info that pertains to a certain case, and the model produces unpredictable results. The paper also splits data collection into three components: development, deployment, and execution.

#### Solution:
Unicorn is a platform that can simplify the data-collection process. The authors describe Unicorn as having three key features: reusability, evolvability, and scalability. Unicorn is intended to be reusable by providing a means through which data-collection pipelines can become isolated "tasks" that can be processed repeatedly and under different conditions. Another key part of Unicorn is its ability to isolate data from its infrastructure; each network system or provider may have a different infrastructure in which its data is stored, part of Unicorn's functionality is to be able to process and combine data from different infrastructure types so that it can all be used to gether to create a more complete model. 

# Week 1
Nothing here so far!
