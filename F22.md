# MYangERSP2223Logs
My logs for ERSP 2022-2023

# Week 3
## Goals
- [] Write goals 

# Week 2

## Goals
- [x] Read Unicorn research paper
- [x] Have first research group meeting / ~~get response on when mentor meetings will occur~~ meeting will occur on 4PM PST October 7
- [x] Get link to logs on the CS110 website
- [x] Reading Log Pass 2
- [x] Decide on teaching topic (DP)

## Research Meeting Notes:
Visited Professor Gupta's office on 5th floor of HFH to discuss initial project, discussed a bit about Unicorn, but more interesting topic was other "trust" based program that can somehow turn black box AI artifacts into decision trees? Initial thoughts are that there's no way in hell that works well (especially not with any CNN for image recog, I just can't see how that could be a decision tree), but if it does, I will be EXTREMELY impressed. We were told of an open source python package that can be used on Colab, so I will probably test it out next weekend (Oct 15). I will probably try a simple Bayes classifier and the 10x10 pixel number recognition.

## Unicorn Research Paper Notes:
### Abstract:
Existing ML solutions for networking problems are not being implemented; this is because these ML artifacts are often unreliable. The paper makes the claim that these ML artifacts have poor quality due to their training data: the process of collecting data for ML is described as "one-off," "fragmented," and with two key issues: it is too difficult to compile data from different sources to use as training material for the same problem, and simultaneously too difficult to apply data from a single source to mutliple problems. The paper proposes a solution called "Unicorn," which sreamlines the process of collecting data from one source for multiple problems.

### Introduction:
Network operators have, at any point, only a partial understanding of the state of their network, and they constantly need to make decisions to solve some arbitrary "problems." There seems to be industry interest in applying ML techniques to better make these decisions, but existing ML solutions are not being applied. This is because the industry feels wary of ML's innate "black-box" nature. The "black-box" issue refers to our lack of understanding regarding neural networks. Although we can use them, we have almost no insight into how they actually make decisions. The ML artifacts created with given data are simply too complicated for a human to understand. Industry members must then rely solely on the algorithm's results to determine its feasibility. In order for the algorithm to be "trustworthy," it must be able to adapt to and properly process information outside of its training set. Existing ML solutions struggle to do so, as they are often trained with data from one, specific source, and often do not correctly generalize to external data.

Everything beyond the background on the problem being solved describes Unicorn's specifications and how it would help solve the above problems. However, I don't have any technical understanding of ML models or data collection pipelines as they are described in the paper.

### Experimental Process:
The paper describes the process of implementing a Unicorn prototype. The paper describes Unicorn's implementation being split into a frontend and backend. The frontend serves as an interface for the user to select and configure data-collection pipelines. An operation titled "execute" will connect these pipelines to Unicorn's backend and begin processing. Unicorn's backend consists of the following components: 
1. Connectivity-manager: connects Unicorn's front and backend
2. Compiler: translates data-collection pipeline's general data into specific forms depending on what problem the artifact will be trained for, then processes the data (not sure how)
3. Runtime: serves as sort of a general OS that handles queries and displays runtime info
4. Datastore: provides memory for the runtime to manage

### Background:
The paper's background and motivation segment discusses two core concepts: the "trust problem" in existing ML approaches, as well as existing data-collection pipelines. The core issue in the described "trust problem" is simple: ML artifacts are unable to generalize beyond their training data set; the paper describes them as unaware of any potential biases that result from their training set. As a result, these ML artifacts fail in two key ways: there are "structural failure modes" where the model consistently provides an incorrect output (the paper calls this a misalignment between selected and desired predictors), then there are "underspecificed failure modes," where the training data doesn't contain info that pertains to a certain case, and the model produces unpredictable results. The paper also splits data collection into three components: development, deployment, and execution.

### Solution:
Unicorn is a platform that can simplify the data-collection process. The authors describe Unicorn as having three key features: reusability, evolvability, and scalability. Unicorn is intended to be reusable by providing a means through which data-collection pipelines can become isolated "tasks" that can be processed repeatedly and under different conditions. Another key part of Unicorn is its ability to isolate data from its infrastructure; each network system or provider may have a different infrastructure in which its data is stored, part of Unicorn's functionality is to be able to process and combine data from different infrastructure types so that it can all be used to gether to create a more complete model. 

### Unknowns:
Not much knowledge on concept of networking, nor what "problems" artifacts trained with unicorn-produced data are aiming to solve

## Reading Log Pass 2
### What is networking
https://www.geeksforgeeks.org/challenges-of-computer-network/

Networking refers to the process of connecting different computers together, as well as how they communicate between one another. Common networking problems have to do with network security (people sending harmful data or attempting to extract important data) and consistency (keeping network connections consistent).

### What is your takeaway message from this paper?
Unicorn is a tool to combine data collection pipelines to more effectively create training datasets for networking ML artifacts.

### What is the motivation for this work (both people and technical problem), and its distillation into a research question? Why doesn't the problem have a trivial solution? What are the previous solutions and why are they inadequate?
Networking is so large-scale, AI is powerful; we should apply AI to solve networking solutions and lower human costs. Existing AI artifacts have poor training data; they resultantly do not properly generalize to real-world scenarios. Existing methods of collecting data do not cover wide enough of a range of info to be effective.

### What is the proposed solution? Why is it believed it will work? How does it represent an improvement? How is the solution achieved?
Unicorn is a proposed system that allows for automated combining and formatting of different data pipelines to one uniform typing; that uniform database can then be selected from and modified again to fit different ML artifact needs. This will result in easier data collection (no hard coding for each pipeline) and collected data being usable across different artifacts.

### What is the author's evaluation of the solution? What logic, argument, evidence, artifacts (e.g., a proof-of-concept system), or experiments are presented in support of the idea?
ML artifact quality improves with quality of training data; the author claims that it is not the ML models that are insufficient, but rather that the data fed to train them is poor. As a result, any system that is capable of doing what the author proposes Unicorn will do must logically improve the overall networking ML artifact landscape. Although author does acknowlede the difficulties of implementing such a solution; their described prototype does yield statistical improvements (less lines of code having to be written per pipeline).

### What is your analysis of the identified problem, idea and evaluation? Is this a good idea? What flaws do you perceive in the work? What are the most interesting or controversial ideas? For work that has practical implications, ask whether this will work, who would want it, what it will take to give it to them, and when it might become a reality?
The idea itself seems good. Logically, the presented problem and proposed solution makes sense; if Unicorn is completed and commercialized, it would be realistic to see many internet providers and large software corporations adopt the technology to create models that better strengthen the security and stability of their internal computer networks (or in the case of internet providers, the networks they provide to ordinary people as a service).

### What are the paper's contributions (author's and your opinion)? Ideas, methods, software, experimental results, experimental techniques...?
The paper's biggest contribution seems to be the creation of a specification for a type of software; it proposes a specific style of solution to a larger problem that others may not have immediately thought of (I would have looked into model quality as opposed to data quality).

### What are the future directions for this research (author's and hours, perhaps driven by shortcomings or other critiques)?
Upon speaking to Professor Gupta, it feels like the research is leaning towards further improvements of the Unicorn prototype as well as other means of increasing overall trust in ML Artifacts, including a separate technology that involves converting some ML artifacts into visualizable decision trees (which seems extremely difficult but also very impressive)

### What questions are you left with? What questions would you like to raise in an open discussion of the work (review interesting and controversial points above)? What do you find difficult to understand? List as many as you can.
Overall remaining questions are mostly about the specifics in how the Unicorn prototype works, as well as what those data collection pipelines look like. So far, that information has not been easily findable online, will likely need Professor's or mentor's help in finding more info.

## Choosing teaching topic for Week 3
I'm leaning towards dynamic programming; I'm not exactly sure how it would fit into our project so far, but because DP is more problem-solving paradigm than specific methodology, I think it's helpful to learn anyway. Helps for interviews as well, which is a bonus.

# Week 1
Nothing here so far!
